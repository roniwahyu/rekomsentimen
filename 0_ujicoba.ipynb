{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "from lxml import objectify\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "#For blog pages\n",
    "res_rest = []\n",
    "for i in range(13):\n",
    "    print(i)\n",
    "    url = 'https://online.datasciencedojo.com/blogs/?blogpage='+str(i)\n",
    "    print(url)\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'lxml')\n",
    "\n",
    "    urls_temp_rest = []\n",
    "    urls_rest=[]\n",
    "    temp_rest=[]\n",
    "#     x='blogs'\n",
    "    for h in soup.find_all('a'):\n",
    "    #     print(h)\n",
    "        a = h.get('href')\n",
    "        urls_temp_rest.append(a)\n",
    "    for i in urls_temp_rest:\n",
    "        if i != None :  \n",
    "            if 'blogs' in i:\n",
    "                if 'blogpage' in i:\n",
    "                    None\n",
    "                else:\n",
    "                    if 'auth' in i:\n",
    "                        None\n",
    "                    else:\n",
    "                        urls_rest.append(i)\n",
    "    [temp_rest.append(x) for x in urls_rest if x not in temp_rest]\n",
    "    for i in temp:\n",
    "        if i=='https://online.datasciencedojo.com/blogs/':\n",
    "            None\n",
    "        else:\n",
    "            res_rest.append(i)\n",
    "    print(res_rest)\n",
    "    print('--------')\n",
    "    \n",
    "    \n",
    "    \n",
    "#Getting name and description\n",
    "name=[]\n",
    "des_temp=[]\n",
    "for j in res_rest:\n",
    "    url = j\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "\n",
    "    metas = soup.find_all('meta')\n",
    "    name.append([ meta.attrs['content'] for meta in metas if 'property' in meta.attrs and meta.attrs['property'] == 'og:title' ])\n",
    "    des_temp.append([ meta.attrs['content'] for meta in metas if 'name' in meta.attrs and meta.attrs['name'] == 'description' ])\n",
    "    \n",
    "    \n",
    "#Removing stop words\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "descrip=[]\n",
    "# des_temp=np.array(des_temp)\n",
    "# print(des_temp)\n",
    "for i in descrip_temp:\n",
    "    for j in i:\n",
    "        text = re.sub(\"@\\S+\", \"\", j)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = re.sub(\"\\$\", \"\", text)\n",
    "        text = re.sub(\"@\\S+\", \"\", text)\n",
    "        text = text.lower()\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])    \n",
    "    descrip.append(text)\n",
    "\n",
    "    \n",
    "    #Building BOW\n",
    "model = Tokenizer()\n",
    "model.fit_on_texts(descrip)\n",
    "rep = model.texts_to_matrix(descrip, mode='count')\n",
    "# print(f'Key : {list(model.word_index.keys())}')\n",
    "rep_name=f'Key : {list(model.word_index.keys())}'\n",
    "\n",
    "\n",
    "#Creating df\n",
    "# name=np.array(name)\n",
    "# name=name.astype(str)\n",
    "df_name=pd.DataFrame(name)\n",
    "df_name.rename(columns = {0:'name'}, inplace = True)\n",
    "df_count=pd.DataFrame(rep)\n",
    "frames=[df_name,df_count]\n",
    "result=pd.concat(frames,axis=1)\n",
    "result=result.set_index('name')\n",
    "result=result.drop([0], axis=1)\n",
    "for i in range(len(rep)):\n",
    "    result.rename(columns = {i+1:i}, inplace = True)\n",
    "\n",
    "    \n",
    "#Calculating cosine similarity\n",
    "df_name=df_name.convert_dtypes(str)\n",
    "a=df_name['name']\n",
    "sim_df = pd.DataFrame(cosine_similarity(result, dense_output=True))\n",
    "for i in range(len(name)):\n",
    "    sim_df.rename(columns = {i:a[i]},index={i:a[i]}, inplace = True)\n",
    "sim_df\n",
    "\n",
    "\n",
    "max_val = sim_df.apply(lambda x: pd.Series(np.concatenate([x.nlargest(11).index.values])), axis=1)\n",
    "max_val\n",
    "max_val.to_csv('E:/DSD/Internal Analytics/Blogs/Suggested Blogs.csv',index=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
